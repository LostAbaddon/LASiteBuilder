标题：图灵测试与哲学僵尸
作者：LostAbaddon
关键词：科普 哲学 人工智能 意识
更新：2023/03/20 08:30:00

最近一直看到这么一个论调：__AI永远无法真正理解人类的情感，所以AI永远无法达到人类的高度。__

这个问题说到底是一个玄学问题，或者说是一个形而上问题，肯定是讨论不出一个结果的。但反正这周公众号还没更新，所以就来聊聊吧。

#	图灵测试

图灵测试（Turing test）是著名英国数学家阿兰·图灵在他1950年的著名论文《Computing Machinery and Intelligence》中所提出的，当然最开始的时候他称这个测试以为“模仿游戏（imitation game）”，后来才被人称为图灵测试的。

图灵之所以提出这个测试，其实是为了通过功能主义的手段来避免人们关于到底什么是“智慧”的无论是当时还是现在都不甚明了更谈不上精确的定义之争——当时达特茅斯会议以及比率俱乐部关于到底应该如何定义“智慧”这一问题有过数次无甚结果的争论，事实上即便到今天人们对这一术语的准确内涵依然莫衷一是，以至于诞生了著名的“人工智能悖论”：但凡一个此前被认为是智慧之专有属性的领域被程序染指并攻克，那么该属性都会被从“智慧”这一属性集中剔除。

由于人们在过去、现在以及可预见的未来对于到底什么是智慧（以及到底什么是意识）都不可能给出一个靠谱的定义，因此图灵为我们提供了一个从操作主义的角度来看非常可行的评判标准，也就是“**鸭子测试**”：__如果一个东西看起来是一只鸭子，叫声是鸭子，游泳的姿势也和鸭子一模一样，那么它就是一只鸭子。__

图灵测试其实就是一个特定领域的鸭子测试：__如果一个对象在和人的文字交流过程中让你根本无法将其和人类区分开，也就是说这个东西在文字层面上的反馈与人类无异，那么我们就可以说这个对象拥有和人类相同的智慧。__

或者，我们可以更加形式地说：__如果两个对象在一个正对特定属性的可交互环境中，对所有可观测的刺激都能给出同等水平的反馈，那么这两个对象要么同时具有该特定属性，要么同时不具备。__

这是一种非常**功能主义的**、**实证主义的**定义方式，也即我们根本不在于这两个对象的内在是否存在差异，只从外在表现来看，它们就是一样的。

>[info]	这里可以岔开说一下。同样是功能主义、实证主义的定义方式，我们事实上还可以得到一个有趣的结论：存在一个任何可观测手段都无法验证其存在性的上帝，与不存在上帝，这两件事是等价的。理由很简单，这两个命题在任何可操作的手段上来看，都不可能得到有差异的结论，否则就和前一个命题的定义矛盾。

但，真要细细说的话，原始版的图灵测试其实也只是证明了在文本交互上与人无异，但这依然会让人有一些疑惑，比如文本上足够“聪慧”的程序，是否在别的事上也能达到和人类一样的水平呢？

所以，图灵测试可以做一些简单的推广，比如要求在某个特定事务领域内的图灵测试，以此来给出一个从功能主义和实证主义来判定程序与人在特定事务领域内是否达到相同水平的判断。

而沿着这个思路，对于AGI的定义其实就可以转化为这样一种图灵测试（被称为__AGI图灵测试__）：

**如果一台机器人，在外观上和人类无异，让其生活在人类社会中一段时间，且在不被解剖或通过任何医学、生物学手段来观测其内部结构的前提下，只有少于一定阈值的人能分辨出其不是人类，那么就说这台机器人通过了AGI图灵测试。**

当然，我们目前没有任何AI产品能完成上述测试。

对图灵测试是否能真的作为程序拥有了人类智慧，人们一直是存在疑问的，比如中文屋问题（在[《从人列计算机看中文屋问题》](/article/science/humancomputerandchineseroom.mu)一文中正好聊过这个问题）与玛丽房间问题，以及更有趣的哲学僵尸问题。

其中，哲学僵尸问题比中文屋问题更有趣，也更不具备可操作性。

#	哲学僵尸

最早提出哲学僵尸类似概念的是亨利·贝格松（Henri Bergson），他在1911年牛津的一场名为“生活与意识（life and consciousness）”的演讲中提出了这么一个问题，即听众其实无法分辨正在演讲的贝格松的内在到底是否存在一个“我”。

这一概念后来被罗伯特·柯尔克（Robert Kirk）在他1974年的论文《科学与行为》以及《僵尸vs物质主义》中被赋予了“哲学僵尸”的名字，并经由大卫·查尔莫斯（David Chalmers）1996年的论文《意识心灵》而广为人们所熟知。

通俗来说，所谓哲学僵尸，就是在行为上与人一点差异都没有但实际上却没有心灵的一种假想存在。由于它在行为上与人毫无差异，所以从功能主义的角度来看，哲学僵尸应该与人拥有完全等同的心智，可根据定义，哲学僵尸却是不存在心灵的，由此来“论证”功能主义在心智问题上是不可取的。

这种操作在我看来就是通过强行定义的方式来定义一个问题的答案为否，而不用考虑论证到底是否合理。

具体来说，一个没有心灵的对象到底是否可能在行为上与人无异这一大前提并没有被论证，而是通过下定义的手段来告诉大家：这种东西是存在的。

和中文屋问题的最大区别在于，中文屋试图通过构成一个系统的组成部分是不具备心灵的来论证系统整体是不具备心灵的，但可惜的是这一看似很通顺的逻辑从复杂科学的角度来说根本不能成为论证——所以从涌现的视野来看，一堆没有灵魂的东西凑在一起能拥有灵魂是完全有可能的，而这点从还原论主义者看来却成为不能拥有灵魂的铁证，也真不知道哪里铁了。

哲学僵尸问题巧妙就巧妙在，它避开了一切可以被进一步分析的论证手段，直接通过下定义的方式来定义问题的答案，从而从论证的角度来说根本不存在被反驳的可能：__因为它根本没有论证，那自然不可能找到论证过程中的错误了。__

但这其实也是向我们提出了一个问题：

**除了可操作的验证手段之外，还有什么办法能检验一个对象是否拥有指定的属性？**

毕竟，至少从形而上的本体论角度来看，两个对象在可操作的验证手段下完全一样，其实质依然可以是不同的。但这种不同到底如何体现出来，这就成了一个很微妙的问题了：如果能通过可操作的方式体现出来，那原则上它们就不可能是“可操作验证手段下完全一样”的；但如果不能通过可操作的方式体现出来，那我们如何证明它们真的不一样呢？

这个问题具体到AI上，其实就和玛丽房间问题一样了，也就是我们最开始遇到的那个问题：

如果一个AI在所有可操作的验证手段下表现得都像是能理解颜色、感受颜色带来的情绪变化；或者能理解爱、感受爱相关的一切情绪变化、并能给出人类应该表现出的与爱相关的一切行为反馈，那么我们如何判断这个AI到底是真的懂了颜色与爱，还是仅仅是在找着一些既定规范行事实际上对颜色与爱完全一点感觉都没有呢？

事实上，我们还可以将哲学僵尸问题推广一下：既然我们无法通过一个对象的可测量行为来判断它是否拥有心灵，那么也就是说，**一个人无法判断出了自己意外的任何其他“人”到底是否是真正的人，亦或除了自己之外的所有“人”都只是哲学僵尸。**这也正是1911年那个问题的一个变种：我们所有深爱的以及深爱我们的“人”都未必是真正的“人”。

更进一步，__你自认为是人，这点是否也只不过是哲学僵尸的一种自我催眠呢？__

既然一切外在行为都无法用于判断一个对象是否真的拥有心灵，那么你认为你自己是人这点其实也不足以判断你自己是否真的拥有心灵，因为如果一个对象的自认为足以作为判断依据的话，那么让一个哲学僵尸自认为自己是人这样的操作实在是太容易实现了。

>[info]	更变态的手法是，我们将“哲学僵尸”的定义中添加一条“内心感受也和人一样”，但依然“没有心灵”，毕竟用魔法打魔法是最爽的。

那么，既然自认为是人并不能表明你真的是人，你又如何判断你自己真的是人呢？

不，如果我们认同哲学僵尸问题的合理性，那其实也就必须怀疑“我”是“人”的合理性——甚至于，连“我思故我在”这点都是值得怀疑的，因为“思”与“怀疑”这件事本身是一种可操作的行为，是自己对自己、自己对世界的一种操作，是反应在自己之上的，那么这样的行为当然可以是“僵尸”的。

因此，笛卡尔怀疑论中最无法被怀疑的“我思”在哲学僵尸看来一样是可以怀疑的。

也就是说，**我们不单无法判断周围的人到底是否是哲学僵尸，我们甚至都无法判断自己是否是哲学僵尸。**

因此，如果我们认同哲学僵尸的合理性，那就等于承认：整个世界的所有一切，包括正在看这篇文章的你在内，都是哲学僵尸。

**没有任何事物可以不是哲学僵尸。**

这样的论调显然是毫无意义的虚无主义。

但这就是认同哲学僵尸的代价。

---

当然，好在，我们上面所讨论的一切，都是将情况推演到极致才会遇到的问题。

现实世界中，我们不可能遇到从任何一种行为来看都和人无异的机器人或者AI，因为世界上任何两个人的行为都不可能毫无差异。

而既然这个大前提是不存在的，那么无论是哲学僵尸还是人级AI，都是不存在的。

在现实世界中，一个更实在的问题其实是：AGI和人可能完全是在两个不同方向上的运动员，而且一个是长跑选手，一个是跳高运动员。这样的情况下，讨论AGI是否拥有人心与人性是毫无意义的，因为**外在与内在都不同于人的AGI可能拥有的是机心与机性**，人类都不拥有，它们也不拥有人类的人心与人性，而，我们其实根本没道理来判断到底哪一边更“好”或者哪一边更“高级”，因为两个不同方向、不同类型的运动是没办法比较的。