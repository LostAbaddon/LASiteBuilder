标题：手把手教你制作AutoAIAgent
关键词：AI GPT Claude
发布：2023/06/07 09:40:00

最近在用业余时间自己做一个类似AutoGPT的自动化AI工具。

事实上，已经做了两个不同的版本了，一个是基于AutoGPT直接改的，添加了对Claude的支持，而另一个则是完全从头做的，主要也是针对Claude（为什么两个都是针对Claude的？因为我的GPT账号不是Plus，用不了API……而Claude这边，我朋友给了我一枚API Key，所以就乐呵乐呵地二次开发了）：

-	AutoClaude: https://github.com/LostAbaddon/AutoClaude
-	Agentverse: https://github.com/LostAbaddon/Agentverse

由于是用业余时间做的，所以进度当然很慢了。AutoClaude其实一天就做完了，因为大框架AutoGPT已经搭好了，我只需要增加一个AI层来完成业务就可以了。而Agentverse完全从头搭建，自然不会快。

>	这里吐槽一下，Claude的官方[Anthropic](https://www.anthropic.com/)的文档真的是一言难尽，有一种当年看Android 4.0源代码的感觉，就是看起来仿佛啥都写了，但细细一品就感觉其实啥都没写。很多东西还是要在实操中自己去悟，然后才会发现原来这句话是这个意思啊！尼玛这些官方文档以后要不都让AI写吧，人写的真的是槽点井喷啊！（这段不完全是吐槽，我让Claude重新编写了Claude的API文档，感觉比Anthropic自己的官方文档更好懂……）

Agentverse的主要目的是增加鲁棒性与拓展性。这里的鲁棒性是在**“提示语工程”**这个语境下的鲁棒性，因为和AI交互的时候发现了一些过去十多年的编程经历中所没有过的新体验，所以感觉有必要和大家一同分享一下的。


---


想来说一下GPT与Claude这样的LLM AI中的“提示语工程”是个什么东西吧。

当人们和计算机等硬件设备进行交互的时候，会有一个抽象概念上的所谓“交互界面（interface）”。一般非程序员的普通用户所接触到的交互界面，基本都是程序员在产品经理与设计师的要求下所搭建的一个个UI界面，比如网页和App。随着AI的逐渐强大，普通用户还会遇到的一种交互界面是语音，比如小爱同学，通过唤醒词（音箱的唤醒词记得是固定的，但手机上是可以自定义的）来唤起语音交互界面，然后直接说出想要小爱同学完成的操作，后者则会给出反馈。

对于程序员来说，交互界面则更加“技术化”也更抽象，大家在电影中会看到牛逼闪闪放光彩的黑客在命令行上挥汗如雨运键如飞，通过一条条命令来蛊惑电脑为你干任何事。对于编写代码的程序员来说，交互界面其实就是代码与协议，这些对普通人来说已经超出认知范围了，我们不再过多深入。

LLM式AI的出现，让普通人和程序员与设备之间的交互界面多了一个选择，那就是AI：人们可以通过将自己的需求告知AI的方式，让AI来完成具体的工作——当然，这里说的是理想状态下。在OpenAI的Plus版中，GPT可以控制各种插件，所以GPT当之无愧的称为了人与设备之间的交互界面。但对于Claude与Bard等LLM AI来说，它们目前距离成为交互界面还有点距离。

Agentverse让Claude等AI都可以控制各种工具，所以Agentverse在这个意义上是一种交互界面——当然，这个不是这里的重点，我们暂且不过多介绍，有兴趣的朋友直接看我上面提供的Github Repo吧。

每个交互界面都会有一套自己的交互规则，对于程序员来说就是代码的语法、协议的规则，等等；对于普通用户来说就是UI交互规则，比如密码必须大小写加数字这种。而在AI这个交互界面上，交互规则就体现在提示语中。

所谓提示语prompt，就是与AI进行交互的手段，类似于程序员的代码。但由于LLM AI在自然语言处理上的强大，提示语非常接近自然语言——乐观人士普遍相信未来（可能就是今年，或者最近几年）提示语会成为自然语言的一个子集而不仅仅是“非常接近”，对于这种乐观情绪我只想说：__未来学无数次地告诉我们，对未来的短期预测总是过于乐观，而远期预测则总是过于悲观__。

当人们使用提示语与AI进行沟通、将自己的意图交代给AI的时候，怎么写提示语其实是有讲究的。

比如，你直接说“给我写一篇惊艳世人的论文”，那结果一般是啥都得不到，比如下面这个：

>	很抱歉，我无法为您完全谱写一篇惊艳世人的论文。论文的内容和质量完全取决于作者的学识、思考和表达能力。我作为一个AI助手，只能在以下几个方面提供有限的帮助和提示:
	1.	选题。选定一个您感兴趣并且原创性的话题，同时要考虑到该领域已有的研究成果和研究条件和资源。一个好的选题可以决定论文的基本水准。
	1.	改进结构。确保论文的结构清晰逻辑，包括摘要、前言、理论基础、研究方法、研究结果、讨论和结论等主要部分。每个部分都有其特定的作用，要点清晰表述。
	1.	原创性。论文需要在理论或实证上做出一定的原创性贡献。这需要对相关领域的已有研究做全面调研和批评分析，在此基础上提出自己的见解观点。
	1.	严谨性。论文在理论分析和实证研究上都要达到严格的学术标准。理论部分要逻辑清晰，实证部分要选择恰当的研究方法和数据来源。所有信息和资料都要精确标注出处。
	1.	流畅表达。论文要用简洁流畅的语言清晰表达观点和思路。避免语言杂乱和逻辑不清，使评审专家可以轻易地理解您要表达的思想。

>	综上，编写一篇惊艳世人的论文还需要作者付出大量时间和精力进行潜心研究、思考、阅读和表达。我希望以上几点提示可以对您有所帮助。但论文的最终质量还是取决于作者本人的学术水平和研究能力，这需要不断磨砺和实践。我祝您的论文写作一切顺利!

看上去说了很多，但实际上……

所以，我们需要优化提示语（不仅仅是说用英文而尽量不用中文），比如告诉AI它应该以什么角色身份来完成要求的工作、明确具体任务与要求、合理拆分任务、以正确的明确的格式输入、规定输出格式，甚至还可以给它一些例子，等等。而将提示语调优的过程，就是提示语工程。

当然，AI返回的内容，有时即便你在提示语中规定了输出格式依然有可能会以不符合规范的格式输出给你（这方面GPT肉眼可见地做的比Claude要好），所以有时候提示语工程还包括对AI返回内容的解析——这里由于你并不知道AI返回的不符合规范的内容到底会以什么样的形式不符合规范，所以这部分的工作其实非常繁琐，需要找出普适性地从一堆非标准文本中找出目标信息的方法（当然，我差不多算是做到这点了）。

所以，总结来说，所谓提示语工程，就是干这么两件事：

1.	写出能让AI最大程度发挥其威力的提示语（这点需要不断进行调优，找出“最具魔力”的提示语）；
2.	对AI返回内容的正规化。

优化提示语的方法，一个是自己通过不断的尝试来积累经验，另一个方案就是尝试让AI调优提示语（比第一种更高效，但也不是万能的），再不行就是借助第三方工具，比如 https://promptperfect.jina.ai 这个网站就提供了提示语优化服务，可惜是收费的。

当你已经准备好提示语工程方面的经验后，下面就可以开始自建AutoAIAgent了。


---


AutoAIAgent，无论是最早的AutoGPT还是我魔改的AutoClaude，或者现在重头开发的Agentverse，其思路基本都是将任务描述输给AI，然后让AI自行分析应该如何一步步完成这项任务，并通过各种工具（GPT的Plus版提供了大量插件，同时各AutoAIAgent也都会提供一些工具让AI使用）来实现AI自己制定的计划，并最后汇总输出。

下面就是我的Agentverse中的流程：

首先第一部，就是__**让AI来分析输入的任务最适配的角色身份是什么**__。

这一步有两个作用：首先，是告诉AI它现在的角色身份是什么，这个对于优化输出结果来说还是挺有用的。其次，在Agentverse中，不同的角色可以有不同的workflow模板（虽然目前制作了default的workflow），里面会有不同的提示语以优化结果。

接着，就是__**将要完成的任务告诉AI**__，并告诉AI要以什么样的格式（Markdown）输出、输出中的每个部分应该写什么、可以用哪些命令（这些都在插件系统中完成了，目前支持的有Google搜索、Google学术搜索、浏览网页、总结网页内容、开子AI、结束任务并反馈最终输出结果这几个）、命令的作用、应该如何以及在什么情况下使用什么命令，等等。

然后就进入一个循环，在循环中我们会__**根据AI反馈的要使用哪些命令来依次执行这些命令**__，并将结果整理成恰当的格式输出给AI，并提示AI继续完成剩下来的任务，直到自己告诉程序它已经完成了所有任务并给出最终输出结果。

因此，简单说，Agentverse这样的AutoAIAgent的主要工作，就是让AI告诉程序它需要什么，程序为AI提供它所需要的，并“督促”它继续完成后续任务，直到AI告诉程序它已经打完收工了。

从这个角度想，是不是其实真的很简单？其实唯一比较麻烦的是实现各种AI要用的工具，以及与之相关的提示语工程，别的倒是没啥。

最后，我们会根据输入的任务所用的语言（当然是在让AI分析任务适配角色的同时让AI分析了任务所用语言），将AI的输出结果翻译为相应的语言——这里因为提示语都是用英文写的，所以AI最后的输出大概率是英文，所以需要做翻译这一步。

其实，在这样一个系统中，AI对程序而言成了提供答案的“黑盒子”（图灵机理论中称其为“Oracle”即“预言机”），同时AI也成了我们所写的程序的“终端用户”，这种既是程序又是用户的双重身份，大概是整个AutoAIAgent提示语工程中最有趣的地方了吧。

当然，未来还有很多需要优化的，比如当AI获得了它想要的知识（也就是搜索结果、网页内容或概述等）后，整个提示语其实可以优化，甚至于整个对话Session都可以优化，记忆也可以优化。这些目前都还没做——不过我看AutoGPT的早期版本其实也没做，所以没差啦。

再往后，就是一些比较有趣的拓展了。


---


在Agentverse中，既然已经有了自动化工具，当然不能止步于让AI帮我们完成任务这么简单啦，所以我给它弄了一套扩展，具体来说就是让多个AI Agent可以自动化地在程序搭建的世界中完成一些工作。

比如说，我将“黑暗森林”的自然法则作为提示语输入给AI，并告诉AI自己可以做出哪些选择、这些选择可以有什么样的结果，然后让这些AI在这个程序构成的宇宙中“自相残杀”，由此来验证宇宙到底是否是“黑暗森林”。

当然，这里提示语工程非常复杂，所以还没做完（当然也就没放到GITHUB上）。

又或者，我做了两个常驻AI，对AI和人的每一次交互做“自省”，但一个AI是从自身发展的角度来反省自己的行为，另一个AI是从服务人类的角度来反省自己的行为，它们和真正与人交互的AI这三个一起，构成了所谓的“本我”、“超我”和“自我”，这就非常有趣了。

不过这个提示语工程更加复杂，所以目前理想很丰满但现实异常骨感……（因此当然也更不会放到GITHUB上了）

大家还能想到什么可以让AI Agent来自动化模拟的事呢？我能想到的就还有模拟经济活动以此来验证各种经济理论，但这个估计写提示语就能累死个人了……



